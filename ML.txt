Screen shot of the Kmers discovery data frame

 X	Class	TGGTTTT	ATAACC	GAATCT
Mp1g00170	pos	1	1	0
Mp1g00410	pos	0	0	0
Mp1g02960	pos	0	0	1
Mp1g05920	pos	0	0	0
Mp1g09120	pos	1	0	1
Mp1g09180	pos	0	0	1
Mp1g09190	pos	1	0	1
Mp1g10690	pos	0	0	1
Mp1g12530	pos	0	0	1


âˆ† due to the update in numpy, the class with 1,0 can not be identified. Therefore, I change the 1,0 with string pos and neg.

# /R4.2.2
library(dplyr)library(pgirmess)library(stringr)dir <- 'full_path_to_folder_of_all_.fa.out.random_df_p0.01.txt'prefix <- 'prefix'middle <- 'neg'ends <- '.fa.out.random_df_p0.01.txt'for ( i in 1:10){  number <- i  df <- read.delim(paste0(dir,paste(prefix, middle, number, sep = '_'), ends))  df$Class <- str_replace_all(df$Class, '1', 'pos') # class 1 replace with postive  df$Class <- str_replace_all(df$Class, '0', 'neg')# class 0 replace with negative    # output result  write.delim(df, paste0(dir,paste(prefix, middle, number, sep = '_'), ends))  } 



(1) clean data
$ for inp in *df_p0.01.txt
> do 
> python ML_preprocess.py -df $inp -na_method median -onehot t
> done


(2) define test set
$ for inp in *df_p0.01_mod.txt
> do 
> python test_set.py -df $inp -use pos,neg -type c -p 0.1 -save $inp.test
> done


(3) select best features as predictor
$ for inp in *df_p0.01_mod.txt
> do 
> python Feature_Selection.py -df $inp -cl_train pos,neg -type c -alg lasso -p 0.01  -save $inp.top_feat_lasso
> done



(4) train

-alg can be RF,SVM, or LogReg

$ for inp in *df_p0.01_mod.txt
> do 
> python ML_classification.py -df $inp -test $inp.test -cl_train pos,neg -alg RF -feat $inp.top_feat_lasso -apply all -plots T
> done







